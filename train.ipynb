{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataset import Dataset\n",
    "\n",
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=gpus[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "input_path = 'train_data/sensor/2018-11-29.csv'\n",
    "target_dir = 'train_data/heatMat/'\n",
    "label_maps = pd.read_csv('data_name_idx.txt', header=None, sep=\"\\t\")\n",
    "trian_gen = Dataset(batch_size, input_path, target_dir, label_maps,trian=True)\n",
    "val_gen = Dataset(batch_size, input_path, target_dir, label_maps,val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = keras.Input(shape=(8,23,27,1))\n",
    "\n",
    "    x = keras.layers.Conv3D(64,(3,3,3),padding='same',activation='relu')(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = keras.layers.Conv3D(64,(3,3,3),padding='same',activation='relu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    # x = keras.layers.Conv3D(64,(3,3,3),padding='same',activation='relu')(x)\n",
    "    # x = keras.layers.BatchNormalization()(x)  \n",
    "    x = keras.layers.Conv3D(64,(3,3,3),padding='same',activation='relu')(x)\n",
    "    x_c1 = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x_c2 = keras.layers.Conv3DTranspose(64,(1,3,3),strides=(1, 2,2), padding='same')(x_c1)\n",
    "    x_c2 = keras.layers.BatchNormalization()(x_c2)\n",
    "    x_c2 = keras.layers.UpSampling3D(size=(1,2,2))(x_c1) + x_c2\n",
    "\n",
    "    x_c2 = keras.layers.Conv3D(64,(1,3,3),padding='same',activation='relu')(x_c2)\n",
    "    x_c2 = keras.layers.BatchNormalization()(x_c2)\n",
    "\n",
    "    x_c3 = keras.layers.Conv3DTranspose(64,(1,3,3),strides=(1, 2,2), padding='same')(x_c2)\n",
    "    x_c3 = keras.layers.BatchNormalization()(x_c3)\n",
    "    x_c3 = keras.layers.UpSampling3D(size=(1,2,2))(x_c2) + x_c3\n",
    "\n",
    "    x_c3 = keras.layers.Conv3D(64,(1,3,3),padding='same',activation='relu')(x_c3)\n",
    "    x_c3 = keras.layers.BatchNormalization()(x_c3)\n",
    "\n",
    "    x_c4 = keras.layers.Conv3DTranspose(64,(1,3,3),strides=(1, 2,2), padding='same')(x_c3)\n",
    "    x_c4 = keras.layers.BatchNormalization()(x_c4)\n",
    "    x_c4 = keras.layers.UpSampling3D(size=(1,2,2))(x_c3) + x_c4\n",
    "\n",
    "    x_c4 = keras.layers.Conv3D(128,(1,3,3),padding='same',activation='relu')(x_c4)\n",
    "\n",
    "    outputs = keras.layers.Conv3D(1,(1,3,3), padding='same')(x_c4)\n",
    "    return keras.Model(inputs,outputs)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_true, y_pred):\n",
    "    y_true = tf.where(y_true<0.9,0.,1.)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n",
    "    return tf.reduce_mean(cross_ent)\n",
    "\n",
    "def my_loss_2(y_true, y_pred):\n",
    "    y_pred_sig = tf.clip_by_value(tf.sigmoid(y_pred),1e-15,1. -1e-15)\n",
    "    y_pos_indx = tf.where(tf.greater_equal(y_true, 0.8))\n",
    "    y_pos_loss = - tf.pow(1. - y_pred_sig, 2) * tf.math.log(y_pred_sig)\n",
    "    pos_loss = tf.reduce_sum(tf.gather_nd(y_pos_loss,y_pos_indx))\n",
    "\n",
    "    y_neg_indx = tf.where(tf.less(y_true, 0.8))\n",
    "    y_neg_loss = - tf.pow(1.- y_true, 4) * tf.pow(y_pred_sig, 2) * tf.math.log(1.-y_pred_sig)  / (1. - y_pred_sig)\n",
    "    neg_loss = tf.reduce_sum(tf.gather_nd(y_neg_loss,y_neg_indx)) \n",
    "    return pos_loss + neg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-4\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=200, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=my_loss_2,\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    ")\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"model_5.h5\", save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "history = model.fit(\n",
    "    trian_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_cb,tensorbord_callback],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_true = val_gen[8]\n",
    "# model.load_weights('model_5.h5')\n",
    "y_pred = model(x)\n",
    "\n",
    "y_pred_sig = tf.clip_by_value(tf.sigmoid(y_pred),1e-15,1. -1e-15)\n",
    "y_pos_indx = tf.where(tf.greater_equal(y_true, 0.8))\n",
    "y_pos_loss1 = - tf.pow(1. - y_pred_sig, 2) * tf.math.log(y_pred_sig)\n",
    "y_pos_loss = tf.reduce_sum(tf.gather_nd(y_pos_loss1,y_pos_indx))\n",
    "print(y_pos_loss.numpy())\n",
    "\n",
    "y_neg_indx = tf.where(tf.less(y_true, 0.8))\n",
    "y_neg_loss1 = - tf.pow(1.- y_true, 4) * tf.pow(y_pred_sig, 2) * tf.math.log(1.-y_pred_sig)  / (1. - y_pred_sig)\n",
    "y_neg_loss = tf.reduce_sum(tf.gather_nd(y_neg_loss1,y_neg_indx))\n",
    "print(y_neg_loss.numpy())"
   ]
  }
 ]
}